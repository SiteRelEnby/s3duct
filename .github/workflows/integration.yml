name: Cloud Integration Tests

on:
  workflow_dispatch:
    inputs:
      simple:
        description: "Basic S3 roundtrip (upload, download, verify)"
        type: boolean
        default: false
      backends:
        description: "All S3-compatible backends (R2, B2, MinIO)"
        type: boolean
        default: false
      huge_file:
        description: "Large file stress test (multi-GB)"
        type: boolean
        default: false
      glacier:
        description: "Glacier lifecycle (upload, thaw, restore)"
        type: boolean
        default: false
      compat:
        description: "Backward compatibility (restore old manifests)"
        type: boolean
        default: false

env:
  S3DUCT_TEST_PREFIX: "ci-${{ github.run_id }}"

jobs:
  # --------------------------------------------------------------------------
  # Simple: basic upload/download/verify on AWS S3
  # --------------------------------------------------------------------------
  simple:
    if: ${{ inputs.simple }}
    runs-on: ubuntu-latest
    environment: aws-live
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      S3DUCT_TEST_BUCKET: ${{ secrets.S3DUCT_TEST_BUCKET }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: |
          pip install -e ".[dev]"
          sudo apt-get install -y age

      - name: Run roundtrip
        run: bash tests/integration/roundtrip.sh

      - name: Cleanup
        if: always()
        run: |
          aws s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-" --recursive 2>/dev/null || true

  # --------------------------------------------------------------------------
  # Backends: test all S3-compatible services
  # --------------------------------------------------------------------------
  backends-minio:
    if: ${{ inputs.backends }}
    runs-on: ubuntu-latest
    services:
      minio:
        image: minio/minio
        ports:
          - 9000:9000
        env:
          MINIO_ROOT_USER: minioadmin
          MINIO_ROOT_PASSWORD: minioadmin
        options: >-
          --health-cmd "mc ready local || exit 1"
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: |
          pip install -e ".[dev]" awscli
          for i in $(seq 1 30); do
            aws --endpoint-url http://localhost:9000 s3 ls 2>/dev/null && break
            sleep 2
          done
          aws --endpoint-url http://localhost:9000 s3 mb s3://s3duct-test
        env:
          AWS_ACCESS_KEY_ID: minioadmin
          AWS_SECRET_ACCESS_KEY: minioadmin
      - name: Run roundtrip
        env:
          AWS_ACCESS_KEY_ID: minioadmin
          AWS_SECRET_ACCESS_KEY: minioadmin
          S3DUCT_TEST_BUCKET: s3duct-test
          S3DUCT_ENDPOINT_URL: http://localhost:9000
        run: bash tests/integration/roundtrip.sh

  backends-r2:
    if: ${{ inputs.backends }}
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      S3DUCT_TEST_BUCKET: ${{ secrets.R2_TEST_BUCKET }}
      S3DUCT_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: pip install -e ".[dev]"
      - name: Run roundtrip
        if: env.AWS_ACCESS_KEY_ID != ''
        run: bash tests/integration/roundtrip.sh
      - name: Skip (no secrets)
        if: env.AWS_ACCESS_KEY_ID == ''
        run: echo "R2 secrets not configured, skipping"
      - name: Cleanup
        if: always() && env.AWS_ACCESS_KEY_ID != ''
        run: |
          pip install awscli
          aws --endpoint-url "${S3DUCT_ENDPOINT_URL}" s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-" --recursive 2>/dev/null || true

  backends-b2:
    if: ${{ inputs.backends }}
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.B2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.B2_SECRET_ACCESS_KEY }}
      S3DUCT_TEST_BUCKET: ${{ secrets.B2_TEST_BUCKET }}
      S3DUCT_ENDPOINT_URL: ${{ secrets.B2_ENDPOINT_URL }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: pip install -e ".[dev]"
      - name: Run roundtrip
        if: env.AWS_ACCESS_KEY_ID != ''
        run: bash tests/integration/roundtrip.sh
      - name: Skip (no secrets)
        if: env.AWS_ACCESS_KEY_ID == ''
        run: echo "B2 secrets not configured, skipping"
      - name: Cleanup
        if: always() && env.AWS_ACCESS_KEY_ID != ''
        run: |
          pip install awscli
          aws --endpoint-url "${S3DUCT_ENDPOINT_URL}" s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-" --recursive 2>/dev/null || true

  # --------------------------------------------------------------------------
  # Huge file: multi-GB stress test
  # --------------------------------------------------------------------------
  huge-file:
    if: ${{ inputs.huge_file }}
    runs-on: ubuntu-latest
    environment: aws-live
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      S3DUCT_TEST_BUCKET: ${{ secrets.S3DUCT_TEST_BUCKET }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: pip install -e ".[dev]"

      - name: Generate 2GB test file
        run: dd if=/dev/urandom of=/tmp/huge-test.bin bs=1M count=2048

      - name: Compute expected hash
        run: sha256sum /tmp/huge-test.bin | cut -d' ' -f1 > /tmp/expected.sha256

      - name: Upload with backpressure
        run: |
          cat /tmp/huge-test.bin | s3duct put \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-huge" \
            --chunk-size 256M \
            --diskspace-limit 1G \
            --tag test=huge-file \
            --no-encrypt

      - name: Download and verify
        run: |
          s3duct get \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-huge" \
            > /tmp/restored.bin
          ACTUAL=$(sha256sum /tmp/restored.bin | cut -d' ' -f1)
          EXPECTED=$(cat /tmp/expected.sha256)
          if [ "$ACTUAL" != "$EXPECTED" ]; then
            echo "HASH MISMATCH: expected=$EXPECTED actual=$ACTUAL"
            exit 1
          fi
          echo "Huge file roundtrip OK: $ACTUAL"

      - name: Cleanup
        if: always()
        run: |
          aws s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-huge/" --recursive 2>/dev/null || true
          rm -f /tmp/huge-test.bin /tmp/restored.bin /tmp/expected.sha256

  # --------------------------------------------------------------------------
  # Glacier: upload to GLACIER, thaw with s3duct restore, download, verify
  # --------------------------------------------------------------------------
  glacier:
    if: ${{ inputs.glacier }}
    runs-on: ubuntu-latest
    environment: aws-live  # requires manual approval
    timeout-minutes: 30    # Expedited restore: 1-5 min
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      S3DUCT_TEST_BUCKET: ${{ secrets.S3DUCT_TEST_BUCKET }}
      AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION || 'us-east-1' }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: pip install -e ".[dev]" awscli

      - name: Generate test data
        run: |
          dd if=/dev/urandom of=/tmp/glacier-input.bin bs=1K count=128 2>/dev/null
          sha256sum /tmp/glacier-input.bin | cut -d' ' -f1 > /tmp/glacier-expected.sha256
          echo "Input SHA256: $(cat /tmp/glacier-expected.sha256)"

      - name: Upload to GLACIER (unencrypted)
        run: |
          cat /tmp/glacier-input.bin | s3duct put \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-plain" \
            --chunk-size 32K \
            --storage-class GLACIER \
            --tag test=glacier \
            --no-encrypt

      - name: Upload to GLACIER (AES + encrypted manifest)
        run: |
          AES_KEY="hex:$(python3 -c 'import os; print(os.urandom(32).hex())')"
          echo "$AES_KEY" > /tmp/glacier-aes-key.txt
          cat /tmp/glacier-input.bin | s3duct put \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-enc" \
            --chunk-size 32K \
            --storage-class GLACIER \
            --key "$AES_KEY" \
            --tag test=glacier-enc

      - name: List streams (should show [GLACIER])
        run: |
          OUTPUT=$(s3duct list --bucket "${S3DUCT_TEST_BUCKET}")
          echo "$OUTPUT"
          echo "$OUTPUT" | grep -q "${S3DUCT_TEST_PREFIX}-glacier-plain" || { echo "FAIL: plain stream not in list"; exit 1; }
          echo "$OUTPUT" | grep -q "GLACIER" || { echo "FAIL: [GLACIER] not in list output"; exit 1; }

      - name: Verify get fails before restore
        run: |
          s3duct get \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-plain" \
            > /dev/null 2>&1 && { echo "FAIL: get should have failed"; exit 1; } \
            || echo "PASS: get correctly failed on unrestored Glacier stream"

      - name: Restore (Expedited, --wait)
        run: |
          s3duct restore \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-plain" \
            --tier Expedited --days 1 \
            --wait --poll-interval 30

      - name: Restore encrypted stream
        run: |
          AES_KEY=$(cat /tmp/glacier-aes-key.txt)
          s3duct restore \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-enc" \
            --key "$AES_KEY" \
            --tier Expedited --days 1 \
            --wait --poll-interval 30

      - name: Download and verify (unencrypted)
        run: |
          s3duct get \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-plain" \
            > /tmp/glacier-restored.bin
          ACTUAL=$(sha256sum /tmp/glacier-restored.bin | cut -d' ' -f1)
          EXPECTED=$(cat /tmp/glacier-expected.sha256)
          if [ "$ACTUAL" != "$EXPECTED" ]; then
            echo "FAIL: hash mismatch (unencrypted)"
            echo "  expected: $EXPECTED"
            echo "  actual:   $ACTUAL"
            exit 1
          fi
          echo "PASS: unencrypted Glacier roundtrip OK"

      - name: Download and verify (encrypted)
        run: |
          AES_KEY=$(cat /tmp/glacier-aes-key.txt)
          s3duct get \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-enc" \
            --key "$AES_KEY" \
            > /tmp/glacier-enc-restored.bin
          ACTUAL=$(sha256sum /tmp/glacier-enc-restored.bin | cut -d' ' -f1)
          EXPECTED=$(cat /tmp/glacier-expected.sha256)
          if [ "$ACTUAL" != "$EXPECTED" ]; then
            echo "FAIL: hash mismatch (encrypted)"
            echo "  expected: $EXPECTED"
            echo "  actual:   $ACTUAL"
            exit 1
          fi
          echo "PASS: encrypted Glacier roundtrip OK"

      - name: Verify integrity
        run: |
          s3duct verify \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-plain"
          AES_KEY=$(cat /tmp/glacier-aes-key.txt)
          s3duct verify \
            --bucket "${S3DUCT_TEST_BUCKET}" \
            --name "${S3DUCT_TEST_PREFIX}-glacier-enc" \
            --key "$AES_KEY"
          echo "PASS: Glacier integrity verified"

      - name: Cleanup
        if: always()
        run: |
          aws s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-glacier-plain/" --recursive 2>/dev/null || true
          aws s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-glacier-enc/" --recursive 2>/dev/null || true
          rm -f /tmp/glacier-*.bin /tmp/glacier-*.sha256 /tmp/glacier-aes-key.txt

  # --------------------------------------------------------------------------
  # Compat: backward compatibility with older manifest versions
  # --------------------------------------------------------------------------
  compat:
    if: ${{ inputs.compat }}
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      S3DUCT_TEST_BUCKET: ${{ secrets.S3DUCT_TEST_BUCKET }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install
        run: pip install -e ".[dev]"

      - name: Test backward compat fixtures
        run: |
          for VERSION_DIR in tests/fixtures/compat/v*/; do
            VERSION=$(basename "$VERSION_DIR")
            echo "Testing compat with $VERSION..."

            STREAM_NAME="${S3DUCT_TEST_PREFIX}-compat-${VERSION}"
            MANIFEST="${VERSION_DIR}/manifest.json"

            if [ ! -f "$MANIFEST" ]; then
              echo "  No manifest.json in $VERSION_DIR, skipping"
              continue
            fi

            # Rewrite manifest s3_keys to use our CI stream name, then upload
            python3 -c "
          import json, sys
          stream = '${STREAM_NAME}'
          m = json.load(open('${MANIFEST}'))
          m['name'] = stream
          for c in m['chunks']:
              fname = c['s3_key'].rsplit('/', 1)[-1]
              c['s3_key'] = f'{stream}/{fname}'
          json.dump(m, sys.stdout)
          " > /tmp/compat-manifest.json
            aws s3 cp /tmp/compat-manifest.json \
              "s3://${S3DUCT_TEST_BUCKET}/${STREAM_NAME}/.manifest.json"

            # Upload chunks
            for CHUNK in "${VERSION_DIR}"/chunks/*; do
              [ -f "$CHUNK" ] || continue
              CHUNK_NAME=$(basename "$CHUNK")
              aws s3 cp "$CHUNK" \
                "s3://${S3DUCT_TEST_BUCKET}/${STREAM_NAME}/${CHUNK_NAME}"
            done

            # Download with current tool and verify
            EXPECTED_HASH=$(cat "${VERSION_DIR}/expected_sha256")
            s3duct get \
              --bucket "${S3DUCT_TEST_BUCKET}" \
              --name "${STREAM_NAME}" \
              > /tmp/compat-restored.bin

            ACTUAL_HASH=$(sha256sum /tmp/compat-restored.bin | cut -d' ' -f1)
            if [ "$ACTUAL_HASH" != "$EXPECTED_HASH" ]; then
              echo "  COMPAT FAIL ($VERSION): expected=$EXPECTED_HASH actual=$ACTUAL_HASH"
              exit 1
            fi
            echo "  $VERSION OK"
            rm -f /tmp/compat-restored.bin /tmp/compat-manifest.json
          done

      - name: Cleanup
        if: always()
        run: |
          aws s3 rm "s3://${S3DUCT_TEST_BUCKET}/${S3DUCT_TEST_PREFIX}-compat-" --recursive 2>/dev/null || true
